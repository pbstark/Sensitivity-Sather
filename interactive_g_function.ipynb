{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity indices for Sobol's G function\n",
    "\n",
    "<!-- dom:AUTHOR: Leif Rune\n",
    "Hellevik -->\n",
    "<!-- Author: -->  \n",
    "**Leif Rune Hellevik**, [leif.r.hellevik@ntnu.no](mailto:leif.r.hellevik@ntnu.no)\n",
    "\n",
    "In this notebook we\n",
    "illustrate how sensitivity indices may be computed\n",
    "for Sobol's G function\n",
    "[Archer et al. 1997](https://www.tandfonline.com/doi/abs/10.1080/00949659708811825). We will demonstrate how both\n",
    "Monte Carlo methods and\n",
    "polynomial chaos expansions may be used to\n",
    "estimate both first order indices and\n",
    "total indices.\n",
    "\n",
    "The G function was chosen as an example for two reasons:\n",
    "\n",
    "* The sensitivity indices have analytical solutions [Saltelli et al. 2010](https://www.sciencedirect.com/user/chooseorg?targetURL=%2Fscience%2Farticle%2Fpii%2FS0010465509003087).\n",
    "\n",
    "* The G function can be used to generate test cases over a wide spectrum of difficulties\n",
    "\n",
    "The notebook has four sections; in the first section the G\n",
    "function is\n",
    "presented along with the analytical expressions for the sensitivity\n",
    "indices. The second and third sections demonstrate how polynomial\n",
    "chaos\n",
    "expansions and Monte Carlo methods may be used to approximate\n",
    "the sensitivity\n",
    "indices. The final section is devoted for comparison\n",
    "of these two numerical\n",
    "approaches.\n",
    "\n",
    "For all sections we make use of the interactive features of the\n",
    "notebooks, which allow you to experiment with how the values of the G\n",
    "function\n",
    "parameters and sample size influence the sensitivity indices\n",
    "for the G function.\n",
    "The intention is to let you gain understanding,\n",
    "experience and intuition in a\n",
    "efficient and convenient manner.\n",
    "\n",
    "Run the first cell to initialise plotting and\n",
    "printing modules for\n",
    "later use (and system settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "# ipython magic\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, inspect\n",
    "# Use this if you want to include modules from a subfolder\n",
    "cmd_subfolder = os.path.realpath(os.path.abspath(os.path.join(os.path.split(inspect.getfile( inspect.currentframe() ))[0],\"python_source\")))\n",
    "if cmd_subfolder not in sys.path:\n",
    "     sys.path.insert(0, cmd_subfolder)\n",
    "\n",
    "%run matplotlib_header\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from present_output import print_vectors_relerror, print_3vectors_relerror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical computation of sensitivity indices for Sobol's G function\n",
    "\n",
    "<div\n",
    "id=\"sec:G_functions\"></div>\n",
    "\n",
    "A function which has proved to be useful as a test\n",
    "function with analytical solutions for the sensitivity indices is Sobol's G\n",
    "function which is defined as:\n",
    "\n",
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Y=G(X) =  G(X_1, X_2,\\ldots,X_k,a_1, a_2,\\ldots,a_k)  =\n",
    "\\prod_{i=1}^{k} g_i \\label{eq:1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "g_i = \\frac{|{4 \\, X_i}-2|+{a}_i}{1+{a}_i} \\label{eq:2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The input factors $X_i$ are assumed to be uniformly\n",
    "distributed in the\n",
    "interval $[0,1]$ with positive real-number coefficients $a_i$ $(a_i \\geq 0).$  The number of\n",
    "factors *k* can be varied as the reader\n",
    "pleases, although the minimum\n",
    "number to produce a meaningful inference is set at\n",
    "three.\n",
    "\n",
    "As you will explore below, the sensitivity $S_i$ of $G(X)$ in\n",
    "([1](#eq:1)) with respect to a specific input factor $X_i$, will depend\n",
    "on the\n",
    "value of the corresponding coefficient $a_i$; small values of\n",
    "$a_i$ (e.g.\n",
    "$a_i=0$) will yield a high corresponding $S_i$, meaning\n",
    "that $X_i$ is an\n",
    "important/influential variable on the variance or\n",
    "uncertainty of $G(X)$.\n",
    "\n",
    "We have\n",
    "implemented Sobol's G function in ([1](#eq:1)) and ([2](#eq:2))\n",
    "in the code\n",
    "snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "# model function\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def g(Xj,aj):\n",
    "    return (np.abs(4*Xj-2.)+aj)/(1+aj)\n",
    "\n",
    "@jit\n",
    "def G(X,a):\n",
    "    G_vector=np.ones(X.shape[0])\n",
    "\n",
    "    for j, aj in enumerate(a):\n",
    "        np.multiply(G_vector,g(X[:,j],aj),G_vector)\n",
    "    return G_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computational efficiency we make use of `just in time` compilation\n",
    "from\n",
    "`numba`. If you have not installed `numba`, you\n",
    "may comment out\n",
    "the lines with `@jit` - the cells will run anyway,\n",
    "albeit probably somewhat slower.\n",
    "\n",
    "The sensitivity indices $S_i$ and $S_{Ti}$ for $Y=G(X)$ in\n",
    "eq.\n",
    "([1](#eq:1)) may be derived as outlined in [Saltelli et al. 2010](https://www.sciencedirect.com/science/article/pii/S0010465509003087).\n",
    "The conditional variance $V_i$ is:\n",
    "\n",
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:Vi\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V_i = V_{X_i} \\left (E_{X_{\\sim i}} (Y \\;| \\;X_{i}) \\right) =\n",
    "\\frac{1/3}{(1+a_i)^2} \\label{eq:Vi} \\tag{3}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<!-- while the conditional variance $V\\left (E(Y \\; | \\; X_{i_1}, X_{i_1},\n",
    "X_{i_1}, \\ldots, X_{i_s}) \\right)$ is given by: -->\n",
    "\n",
    "<!-- !bt -->\n",
    "<!--\n",
    "\\begin{equation} -->\n",
    "<!-- V\\left (E(Y \\; | \\; X_{i_1}, X_{i_1}, X_{i_1}, \\ldots,\n",
    "X_{i_s}) \\right) = \\prod_{j=1}^{s} \\left (1 + V_j \\right) -1 <div\n",
    "id=\"eq:Vscond\"></div> -->\n",
    "<!-- \\end{equation} -->\n",
    "<!-- !et -->\n",
    "\n",
    "while the\n",
    "$V_{T_I}$ and the total variance $V$ are given by:\n",
    "\n",
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:4\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V_{T_i} = V_i \\; \\prod_{j\\neq i} (1+V_j) \\qquad \\text{and}\n",
    "\\qquad V = \\prod_{i=1}^k (1+V_i) -1\n",
    "\\label{eq:4} \\tag{4}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Consequently the first order sensitivity indices $S_i$ of $Y=G(X)$, are given by\n",
    "\n",
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "S_i=\\frac{V_i}{V}\n",
    "\\label{_auto1} \\tag{5}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<!-- The expressions for the variance obtained when keeping one parameter -->\n",
    "<!-- fixed and varying all the others can be found below alow with the -->\n",
    "<!--\n",
    "expression for the total variance.  The Sensitivity indices -->\n",
    "<!-- expressions\n",
    "can be easily retrieved from these. -->\n",
    "\n",
    "In the code snippet below one can\n",
    "interactively experiment how the values of $a_i$ affect the correspoding\n",
    "$S_i$, i.e the\n",
    "sensitivity of $G$ with respect to $X_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "# Analytical computations\n",
    "f, ax = plt.subplots(1,1)\n",
    "f.suptitle('G function variable a coefficients')\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "\n",
    "def Vi(ai):\n",
    "    return 1/(3*(1+ai)**2)\n",
    "\n",
    "def V(a_prms):\n",
    "    D=1\n",
    "    for a in a_prms:\n",
    "        D*=(1+Vi(a))     \n",
    "    return D-1\n",
    "\n",
    "def S_i(ai,a):\n",
    "    return Vi(ai)/V(a)\n",
    "\n",
    "def S_T(ai,a):\n",
    "    Dtot=V(a)\n",
    "    return (Dtot+1)/(Vi(ai)+1)*Vi(ai)/Dtot\n",
    "\n",
    "def update_Sobol(**kwargs):\n",
    "    ax.clear()\n",
    "    for key, value in kwargs.items(): #find indx and value for a_prms\n",
    "        pre,post = key.split(\"a\")\n",
    "        assert pre==\"\"\n",
    "        a_prms[int(post)] = value\n",
    "    \n",
    "    width=0.4\n",
    "    x_tick_list=np.arange(len(a_prms))+1\n",
    "    ax.set_xticks(x_tick_list+width/2)\n",
    "    x_labels=['x'+str(i) for i in np.arange(len(a_prms))]\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylim(0,1)\n",
    "    \n",
    "    for i, a in enumerate(a_prms):\n",
    "        Si[i]=S_i(a,a_prms)\n",
    "        ST[i]=S_T(a,a_prms)\n",
    "        \n",
    "    ax.bar(x_tick_list,Si,width,color='blue')\n",
    "    ax.bar(x_tick_list+width,ST,width,color='red')        \n",
    "    ax.legend(['First order indices','Total indices'])\n",
    "\n",
    "\n",
    "# Analytical sliders\n",
    "k=4 #number of prms\n",
    "a_lbls=['a'+str(i) for i in np.arange(k)]\n",
    "Si=np.zeros(k)\n",
    "ST=np.zeros(k)\n",
    "a_prms=np.zeros(k)\n",
    "\n",
    "import ipywidgets as widgets    \n",
    "my_sliders=[]\n",
    "for i in range(k):\n",
    "    my_sliders.append(widgets.FloatSlider(min=0, max=15, value=6.52, description=a_lbls[i]))\n",
    "\n",
    "slider_dict = {slider.description:slider for slider in my_sliders}\n",
    "ui_left = widgets.VBox(my_sliders[0::2]) \n",
    "ui_right = widgets.VBox(my_sliders[1::2])\n",
    "ui=widgets.HBox([ui_left,ui_right])\n",
    "\n",
    "out=widgets.interactive_output(update_Sobol, slider_dict) \n",
    "display(ui,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you observe the effect stated above, that small\n",
    "values of\n",
    "$a_i$ (e.g. $a_i=0$) will yield high corresponding $S_i$? You may\n",
    "change all the parameters simultaneously or one at the time.\n",
    "\n",
    "You may also\n",
    "change the number of parameters *k* directly in the\n",
    "python-code, however note\n",
    "that this will affect the\n",
    "computing time. In particular, the\n",
    "computing time for the numerical\n",
    "approximations with *chaospy* will be sensitive\n",
    "to *k*.\n",
    "\n",
    "If more than one factor has low $a_i$, high order interactions among factors will\n",
    "be tangible.\n",
    "\n",
    "* The extreme case is setting all $a_i$’s to zero. In this circumstance, all factors will interact and will be of equal importance -> check it out!\n",
    "\n",
    "* How would you assess a setting with only some $a_i$’s are zero and all others are large (e.g. $a_i \\geq 9$ )?\n",
    "\n",
    "Note that the G function has a singularity in each of its $k$ dimensions corresponding to the points $X_i = 1/2$.  \n",
    "\n",
    "## Approximation of the sensitivity indices for Sobol's G function with spectral expansions\n",
    "\n",
    "In this section we show how the spectral expansion module [chaospy](https://github.com/jonathf/chaospy) may\n",
    "be used to compute the Sobol indices for Sobol's G function.  A more in-depth treatment of\n",
    "`chaospy` and its usage is provided in the separate notebook [A\n",
    "practical introduction to polynomial chaos with the1 `chaospy`\n",
    "package](introduction_gpc.ipynb). Furthermore, you may find our previous \"A\n",
    "Guide to Uncertainty Quantification and Sensitivity Analysis for\n",
    "Cardiovascular\n",
    "Applications\" [Eck et al. 2015](https://onlinelibrary.wiley.com/doi/full/10.1002/cnm.2755) as a useful\n",
    "introduction to how polynomial chaos expansions may be used for\n",
    "UQ&S. We are therefore focusing on\n",
    "the application of the spectral\n",
    "expansions and how this benchmarks against the\n",
    "analytical solutions for the\n",
    "indices, rather than presenting the spectral\n",
    "expansion theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "# Si with chaospy for G-function\n",
    "import chaospy as cp\n",
    "cp.seed(0)    \n",
    "jpdf = cp.Iid(cp.Uniform(),k)\n",
    "    \n",
    "polynomial_order = 4\n",
    "poly = cp.orth_ttr(polynomial_order, jpdf)\n",
    "\n",
    "#Ns=2*len(poly)\n",
    "Ns=500\n",
    "print('Number of samples for chaospy: ', Ns) \n",
    "X=jpdf.sample(Ns)\n",
    "G_sample=G(X.transpose(),a_prms)\n",
    "\n",
    "approx = cp.fit_regression(poly, X, G_sample)\n",
    "\n",
    "exp_pc = cp.E(approx, jpdf)\n",
    "std_pc = cp.Std(approx, jpdf)\n",
    "print(\"Statistics polynomial chaos\\n\")\n",
    "print('\\n        E(Y)  |  std(Y) \\n')\n",
    "print('pc  : {:2.5f} | {:2.5f}'.format(float(exp_pc), std_pc))\n",
    "S_pc = cp.Sens_m(approx, jpdf) #Si from chaospy\n",
    "S_tpc = cp.Sens_t(approx, jpdf) #Total effect sensitivity index from chaospy\n",
    "row_labels= ['S_'+str(idx) for idx in range(k)]\n",
    "col_labels=['Chaospy','Analytical','Error (%)']\n",
    "\n",
    "\n",
    "print(\"\\nFirst Order Indices\")\n",
    "\n",
    "print_vectors_relerror(S_pc,Si,col_labels,row_labels,[3,3,0])\n",
    "\n",
    "print(\"\\n\\nTotal Effect Indices\")\n",
    "row_labels= ['St_'+str(idx) for idx in range(k)]\n",
    "print_vectors_relerror(S_tpc,ST,col_labels,row_labels,[3,3,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code-snippet above we compare both the first order indices `S_pc` and the\n",
    "total indices `S_tpc` computed with chaospy, and print them in columns along\n",
    "side the analytical indices and the relative errors. You may experiment how the\n",
    "error is affected by the number of samples `Ns`.\n",
    "\n",
    "### Spectral expansions for computation of  Sobol's sensitivity indices\n",
    "\n",
    "To better facilitate and encourage\n",
    "your experimentation with the impact of changes in the coefficients $a_i$,\n",
    "number of samples, and polynomial order for the spectral expansions in the\n",
    "chaospy module, we make use of interactive widgets with sliders for all these\n",
    "coefficients and variables.\n",
    "\n",
    "Run the code snippet below, and you will see\n",
    "sliders for $a_i$, number\n",
    "of samples `NS` and polynomial order. Once you change\n",
    "one of the slider\n",
    "values, the chaospy approximations of the sensitivity indices\n",
    "is recomputed and the new results will be presented. Bear in mind that\n",
    "the computational time is dependent on the number of samples and the\n",
    "_cpu_ capacity of the machine you are running this notebook on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [],
   "source": [
    "# chaospy G-function with sliders\n",
    "import chaospy as cp\n",
    "\n",
    "if not 'jpdf' in globals():\n",
    "    jpdf = cp.Iid(cp.Uniform(),k) #the joint pdf\n",
    "    print('Create the joint pdf')\n",
    "\n",
    "\n",
    "def update_chaospy_G(**kwargs):\n",
    "    NS=kwargs['NS']\n",
    "    del kwargs['NS']\n",
    "    polynomial_order=kwargs['polynomial_order']\n",
    "    del kwargs['polynomial_order']\n",
    "    \n",
    "    for key, value in kwargs.items(): #find indx and value for a_prms\n",
    "        pre,post = key.split(\"a\")\n",
    "        assert pre==\"\"\n",
    "        a_prms[int(post)] = value\n",
    "    \n",
    "    X=jpdf.sample(NS)\n",
    "    print('Number of samples: ',NS)\n",
    "\n",
    "    G_sample=G(X.transpose(),a_prms)\n",
    "\n",
    "    poly = cp.orth_ttr(polynomial_order, jpdf)\n",
    "    approx = cp.fit_regression(poly, X, G_sample)\n",
    "\n",
    "    exp_pc = cp.E(approx, jpdf)\n",
    "    std_pc = cp.Std(approx, jpdf)\n",
    "    print(\"Statistics polynomial chaos\\n\")\n",
    "    print('\\n        E(Y)  |  std(Y) \\n')\n",
    "    print('pc  : {:2.5f} | {:2.5f}'.format(float(exp_pc), std_pc))\n",
    "    S_pc = cp.Sens_m(approx, jpdf) #Si from chaospy\n",
    "    S_tpc = cp.Sens_t(approx, jpdf) #Total effect sensitivity index from chaospy\n",
    "    \n",
    "    row_labels= ['S_'+str(idx) for idx in range(len(a_prms))]\n",
    "    col_labels=['Chaospy','Analytical','Error (%)']\n",
    "\n",
    "    print(\"\\nFirst Order Indices\")\n",
    "    print_vectors_relerror(S_pc,Si,col_labels,row_labels,[3,3,0])\n",
    "\n",
    "    print(\"\\n\\nTotal Effect Indices\")\n",
    "    row_labels= ['St_'+str(idx) for idx in range(k)]\n",
    "    print_vectors_relerror(S_tpc,ST,col_labels,row_labels,[3,3,0])\n",
    "\n",
    "\n",
    "if (len(my_sliders)==len(a_prms)):   #add sliders if not added before\n",
    "    my_sliders.append(widgets.IntSlider(min=500,max=5100,step=250,value=500,description='NS')) #add slider for samples\n",
    "    my_sliders.append(widgets.IntSlider(description='polynomial_order', min=1,max=6,value=4)) # add slider for polynomial order\n",
    "\n",
    "    slider_dict = {slider.description:slider for slider in my_sliders} #add the sliders in the dictionary \n",
    "\n",
    "    ui_left = widgets.VBox(my_sliders[0::2]) \n",
    "    ui_right = widgets.VBox(my_sliders[1::2])\n",
    "    ui=widgets.HBox([ui_left,ui_right])\n",
    "\n",
    "\n",
    "out=widgets.interactive_output(update_chaospy_G, slider_dict) \n",
    "display(ui,out)\n",
    "\n",
    "# end chaospy G-function with sliders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo simulations for computation of sensitivity indices\n",
    "\n",
    "The snippet of code below allows to evaluate the Sobol sensitivity indices for the same $G$ function in a Monte Carlo simulation. In analogy with the previous example, one can again vary the $a_i$ coefficients along with the number of runs of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [],
   "source": [
    "# Si with monte carlo for G-function\n",
    "\n",
    "import monte_carlo as mc\n",
    "a_prms=np.ones(k)\n",
    "\n",
    "if not 'jpdf' in globals():\n",
    "    cp.seed(0)\n",
    "    jpdf = cp.Iid(cp.Uniform(),k) #the joint pdf\n",
    "    print('Create the joint pdf')\n",
    "\n",
    "def update_mc_G(**kwargs):\n",
    "    Ns=kwargs['NS']\n",
    "    del kwargs['NS']\n",
    "    \n",
    "    for key, value in kwargs.items(): #find indx and value for a_prms\n",
    "        pre,post = key.split(\"a\")\n",
    "        assert pre==\"\"\n",
    "        a_prms[int(post)] = value\n",
    "        \n",
    "\n",
    "\n",
    "    print('Number of samples for Monte Carlo: ', Ns) \n",
    "    X=jpdf.sample(Ns)\n",
    "    A, B, C = mc.generate_sample_matrices_mc(Ns, k, jpdf, sample_method='R') #A, B, C already transposed\n",
    "    G_A_sample = G(A, a_prms)\n",
    "    G_B_sample = G(B, a_prms)\n",
    "    G_C_sample_list = np.array([G(C_i, a_prms) for C_i in C]).T\n",
    "    \n",
    "    exp_mc = np.mean(G_A_sample)\n",
    "    std_mc = np.std(G_A_sample)\n",
    "    print(\"Statistics Monte Carlo\\n\")\n",
    "    print('\\n        E(Y)  |  std(Y) \\n')\n",
    "    print('mc  : {:2.5f} | {:2.5f}'.format(float(exp_mc), std_mc))\n",
    "    \n",
    "    S_mc, S_tmc = mc.calculate_sensitivity_indices_mc(G_A_sample, G_B_sample, G_C_sample_list)\n",
    "    row_labels= ['S_'+str(idx) for idx in range(k)]\n",
    "    col_labels=['Monte carlo','Analytical','Error (%)']\n",
    "    \n",
    "    print(\"\\nFirst Order Indices\")\n",
    "    import analytical_g_function as agf\n",
    "    \n",
    "    Si=np.zeros(k)\n",
    "    ST=np.zeros(k)\n",
    "    for i, a in enumerate(a_prms):\n",
    "        Si[i]=agf.S_i(a,a_prms)\n",
    "        ST[i]=agf.S_T(a,a_prms)\n",
    "     \n",
    "    print_vectors_relerror(S_mc, Si, col_labels, row_labels, [3,3,0])\n",
    "    \n",
    "    print(\"\\n\\nTotal Effect Indices\")\n",
    "    row_labels= ['St_'+str(idx) for idx in range(k)]\n",
    "    print_vectors_relerror(S_tmc, ST, col_labels, row_labels, [3,3,0])\n",
    "\n",
    "## Set up the sliders \n",
    "mc_sliders=[]\n",
    "for i in range(k):\n",
    "    mc_sliders.append(widgets.FloatSlider(min=0, max=15, value=6.52, description=a_lbls[i]))\n",
    "\n",
    "mc_sliders.append(widgets.IntSlider(min=500,max=25000,step=250,value=500,description='NS')) #add slider for samples\n",
    "    \n",
    "slider_dict = {slider.description:slider for slider in mc_sliders} #add the sliders in the dictionary \n",
    "\n",
    "ui_left = widgets.VBox(mc_sliders[0::2]) \n",
    "ui_right = widgets.VBox(mc_sliders[1::2])\n",
    "ui=widgets.HBox([ui_left,ui_right])\n",
    "\n",
    "out=widgets.interactive_output(update_mc_G, slider_dict) \n",
    "display(ui,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of MC and PC for sensitivity indices computations\n",
    "\n",
    "Finally, the performance of the two approaches can be compared by benchmarking against the analytical values of the indices. Which approach performs better? Under which combination of $a_i$ coefficients? How many runs are required in order to get an error below a given threshold (e.g. 5%, 1%)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [],
   "source": [
    "# Si comparison of mc and pc for G-function\n",
    "\n",
    "import monte_carlo as mc\n",
    "a_prms=np.ones(k)\n",
    "\n",
    "if not 'jpdf' in globals():\n",
    "    cp.seed(0)\n",
    "    jpdf = cp.Iid(cp.Uniform(),k) #the joint pdf\n",
    "    print('Create the joint pdf')\n",
    "\n",
    "def update_cmp(**kwargs):\n",
    "    NsMC=kwargs['NsMC']\n",
    "    del kwargs['NsMC']\n",
    "\n",
    "    NsPC=kwargs['NsPC']\n",
    "    del kwargs['NsPC']\n",
    "    \n",
    "    for key, value in kwargs.items(): #find indx and value for a_prms\n",
    "        pre,post = key.split(\"a\")\n",
    "        assert pre==\"\"\n",
    "        a_prms[int(post)] = value\n",
    "        \n",
    "    ## Monte Carlo update\n",
    "    print('Number of samples for Monte Carlo: ', NsMC) \n",
    "    X_mc=jpdf.sample(NsMC)\n",
    "    A, B, C = mc.generate_sample_matrices_mc(NsMC, k, jpdf, sample_method='R') #A, B, C already transposed\n",
    "    G_A_sample = G(A, a_prms)\n",
    "    G_B_sample = G(B, a_prms)\n",
    "    G_C_sample_list = np.array([G(C_i, a_prms) for C_i in C]).T\n",
    "    \n",
    "    exp_mc = np.mean(G_A_sample)\n",
    "    std_mc = np.std(G_A_sample)\n",
    "    print(\"Statistics Monte Carlo\\n\")\n",
    "    print('\\n        E(Y)  |  std(Y) \\n')\n",
    "    print('mc  : {:2.5f} | {:2.5f}'.format(float(exp_mc), std_mc))\n",
    "    \n",
    "    S_mc, S_tmc = mc.calculate_sensitivity_indices_mc(G_A_sample, G_B_sample, G_C_sample_list)\n",
    "    \n",
    "    ## PC update\n",
    "    Xpc=jpdf.sample(NsPC)\n",
    "    G_sample=G(Xpc.transpose(),a_prms)\n",
    "\n",
    "    approx = cp.fit_regression(poly, Xpc, G_sample)\n",
    "    \n",
    "    exp_pc = cp.E(approx, jpdf)\n",
    "    std_pc = cp.Std(approx, jpdf)\n",
    "    print(\"Statistics polynomial chaos\\n\")\n",
    "    print('\\n        E(Y)  |  std(Y) \\n')\n",
    "    print('pc  : {:2.5f} | {:2.5f}'.format(float(exp_pc), std_pc))\n",
    "    S_pc = cp.Sens_m(approx, jpdf) #Si from chaospy\n",
    "    S_tpc = cp.Sens_t(approx, jpdf) #Total effect sensitivity index from chaospy\n",
    "\n",
    "    import analytical_g_function as agf\n",
    "    Si=np.zeros(k)\n",
    "    ST=np.zeros(k)\n",
    "    for i, a in enumerate(a_prms):\n",
    "        Si[i]=agf.S_i(a,a_prms)\n",
    "        ST[i]=agf.S_T(a,a_prms)\n",
    "    \n",
    "    row_labels= ['S_'+str(idx) for idx in range(k)]\n",
    "    col_labels=['Monte Carlo','Err (%)','PolyChaos','Err (%)']\n",
    "    \n",
    "    print(\"\\nFirst Order Indices\")\n",
    "    print_3vectors_relerror(S_mc,S_pc, Si, col_labels, row_labels, [3,0,3,0])\n",
    "    \n",
    "    print(\"\\n\\nTotal Effect Indices\")\n",
    "    row_labels= ['St_'+str(idx) for idx in range(k)]\n",
    "    print_3vectors_relerror(S_tmc,S_tpc, ST, col_labels, row_labels, [3,0,3,0])\n",
    "\n",
    "## Set up the sliders \n",
    "cmp_sliders=[]\n",
    "for i in range(k):\n",
    "    cmp_sliders.append(widgets.FloatSlider(min=0, max=15, value=6.52, description=a_lbls[i]))\n",
    "\n",
    "cmp_sliders.append(widgets.IntSlider(min=500,max=100000,step=250,value=500,description='NsMC')) #slider for MC samples\n",
    "cmp_sliders.append(widgets.IntSlider(min=500,max=2000,step=250,value=500,description='NsPC')) #slider for PC samples\n",
    "    \n",
    "slider_dict = {slider.description:slider for slider in cmp_sliders} #add the sliders in the dictionary \n",
    "\n",
    "ui_left = widgets.VBox(cmp_sliders[0::2]) \n",
    "ui_right = widgets.VBox(cmp_sliders[1::2])\n",
    "ui=widgets.HBox([ui_left,ui_right])\n",
    "\n",
    "out=widgets.interactive_output(update_cmp, slider_dict) \n",
    "display(ui,out)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
